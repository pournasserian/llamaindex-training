{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1515e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "# Prompt for key if missing\n",
    "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
    "    os.environ[\"OPENROUTER_API_KEY\"] = getpass.getpass(\"OPENROUTER_API_KEY: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec843d6c",
   "metadata": {},
   "source": [
    "### Basic Agent Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27ea275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.openrouter import OpenRouter\n",
    "\n",
    "llm = OpenRouter(\n",
    "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "    model=\"anthropic/claude-3.5-sonnet\",\n",
    "    is_chat_model=True,\n",
    "    is_function_calling_model=True\n",
    ")\n",
    "\n",
    "# Define a simple calculator tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Useful for multiplying two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# Create an agent workflow with our calculator tool\n",
    "agent = FunctionAgent(\n",
    "    tools=[multiply],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that can multiply two numbers.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e710bb1",
   "metadata": {},
   "source": [
    "### Adding Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a22b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Logan! I am an assistant that can help you multiply numbers together. Would you like me to multiply any numbers for you? Just let me know which numbers you'd like me to multiply and I'll help you calculate the result.\n",
      "Your name is Logan.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "# create context\n",
    "ctx = Context(agent)\n",
    "\n",
    "# run agent with context\n",
    "response = await agent.run(\"My name is Logan\", ctx=ctx)\n",
    "print(str(response))\n",
    "\n",
    "response = await agent.run(\"What is my name?\", ctx=ctx)\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
